name: Backup Database to Azure Storage

on:
  workflow_dispatch:
    inputs:
      overwriteThisMorningsBackup:
        required: true
        type: boolean
        default: false
      restoreToProductionDataEnv:
        required: true
        type: boolean
        default: false
      restoreToProductionAnalysisEnv:
        required: true
        type: boolean
        default: false
  schedule: # 03:00 UTC
    - cron: '0 3 * * *'

jobs:
  backup:
    name: Backup PaaS Database (production)
    if: ${{ github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.overwriteThisMorningsBackup == 'true') }}
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:11.10
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
        - 5432:5432
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5
    steps:
    - uses: actions/checkout@v3
      name: Checkout

    - name: Set KV environment variables
      run: |
        tf_vars_file=terraform/workspace-variables/production.tfvars.json
        echo "key_vault_name=$(jq -r '.key_vault_name' ${tf_vars_file})" >> $GITHUB_ENV
        echo "key_vault_infra_secret_name=$(jq -r '.key_vault_infra_secret_name' ${tf_vars_file})" >> $GITHUB_ENV
        echo "paas_space_name=$(jq -r '.paas_space_name' ${tf_vars_file})" >> $GITHUB_ENV

    - uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS_PRODUCTION }}

    - uses: DFE-Digital/keyvault-yaml-secret@v1
      id: get-secrets
      with:
        keyvault: ${{ env.key_vault_name }}
        secret: ${{ env.key_vault_infra_secret_name }}
        key: CF_USER,CF_PASSWORD

    - name: Setup cf cli
      uses: DFE-Digital/github-actions/setup-cf-cli@master
      with:
        CF_USERNAME:   ${{ steps.get-secrets.outputs.CF_USER }}
        CF_PASSWORD:   ${{ steps.get-secrets.outputs.CF_PASSWORD }}
        CF_SPACE_NAME: ${{ env.paas_space_name }}
        INSTALL_CONDUIT: true

    - name: Setup postgres client
      uses: DFE-Digital/github-actions/install-postgres-client@master

    - name: Set environment variable
      run: echo "BACKUP_FILE_NAME=register_prod_$(date +"%F")" >> $GITHUB_ENV

    - name: Backup Prod DB
      run: |
        cf conduit register-postgres-13-production -- pg_dump -E utf8 --clean --if-exists --no-owner --verbose --no-password -f ${BACKUP_FILE_NAME}.sql
        tar -cvzf ${BACKUP_FILE_NAME}.tar.gz ${BACKUP_FILE_NAME}.sql

    - name: Set Connection String
      run: |
        STORAGE_CONN_STR="$(az keyvault secret show --name REGISTER-BACKUP-STORAGE-CONNECTION-STRING --vault-name ${{ env.key_vault_name }} | jq -r .value)"
        echo "::add-mask::$STORAGE_CONN_STR"
        echo "STORAGE_CONN_STR=$STORAGE_CONN_STR" >> $GITHUB_ENV

    - name: Upload Backup to Azure Storage
      run: |
        az storage blob upload --container-name prod-db-backup \
        --file ${BACKUP_FILE_NAME}.tar.gz --name ${BACKUP_FILE_NAME}.tar.gz --overwrite \
        --connection-string '${{ env.STORAGE_CONN_STR }}'

    - name: Sanitise the Database backup
      run: |
        echo "::group::Restore backup to intermediate database"
        createdb ${DATABASE_NAME} && psql -f ${{ env.BACKUP_FILE_NAME }}.sql -d ${DATABASE_NAME}
        echo "::endgroup::"

        echo "::group::Sanitise user data"
        psql -d ${DATABASE_NAME} -f db/scripts/sanitise.sql
        echo "::endgroup::"

        echo "::group::Backup Sanitised Database"
        pg_dump --encoding utf8 --clean --no-owner --if-exists -d ${DATABASE_NAME} -f backup_sanitised.sql
        echo "::endgroup::"
      env:
        DATABASE_NAME: register_trainee_teachers
        PGUSER:  postgres
        PGPASSWORD: postgres
        PGHOST: localhost
        PGPORT: 5432

    - name: Upload Sanitised Backup
      uses: actions/upload-artifact@v3
      with:
        name: backup_sanitised
        path: backup_sanitised.sql
        retention-days: 3

    - name: Restore backup to productiondata
      if: ${{ github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.restoreToProductionDataEnv == 'true') }}
      run: |
        cf conduit register-postgres-13-productiondata -- psql < ${{ env.BACKUP_FILE_NAME }}.sql

    - name: Restore backup to analysis
      if: ${{ github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.restoreToProductionAnalysisEnv == 'true') }}
      run: |
        cf conduit register-postgres-analysis -- psql < ${{ env.BACKUP_FILE_NAME }}.sql
        rm ${BACKUP_FILE_NAME}.sql
