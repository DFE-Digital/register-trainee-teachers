name: Backup Database to Azure Storage
concurrency: build_and_deploy_main

on:
  workflow_dispatch:
    inputs:
      environment:
        description: Environment to backup. No sanitised backup or restore will occur.
        required: true
        default: qa
        type: choice
        options:
          - qa
          - staging
          - sandbox
          - production
          - productiondata
      backup-file:
        description: |
          Backup file name (without extension). Default is rtt_[env]_adhoc_YYYY-MM-DD. Set it explicitly when backing up a point-in-time (PTR) server. (Optional)
        required: false
        type: string
        default: default
      db-server:
        description: |
          Name of the database server. Default is the live server. When backing up a point-in-time (PTR) server, use the full name of the PTR server. (Optional)
  schedule: # 03:15 UTC
    - cron: '15 3 * * *'

permissions:
  id-token: write

env:
  SERVICE_NAME: register
  SERVICE_SHORT: rtt
  TF_VARS_PATH: terraform/aks/workspace-variables

jobs:
  backup:
    name: Backup AKS Database
    runs-on: ubuntu-latest
    environment:
      name: ${{ inputs.environment || 'production' }}
    env:
      DEPLOY_ENV: ${{ inputs.environment || 'production'  }}
      BACKUP_FILE: ${{ inputs.backup-file || 'schedule'  }}

    steps:
    - uses: actions/checkout@v4
      name: Checkout

    - name: Set environment variables
      run: |
        source global_config/${DEPLOY_ENV}.sh
        tf_vars_file=${TF_VARS_PATH}/${DEPLOY_ENV}.tfvars.json
        echo "CLUSTER=$(jq -r '.cluster' ${tf_vars_file})" >> $GITHUB_ENV
        echo "NAMESPACE=$(jq -r '.namespace' ${tf_vars_file})" >> $GITHUB_ENV
        echo "RESOURCE_GROUP_NAME=${RESOURCE_NAME_PREFIX}-${SERVICE_SHORT}-${CONFIG_SHORT}-rg" >> $GITHUB_ENV
        echo "STORAGE_ACCOUNT_NAME=${RESOURCE_NAME_PREFIX}${SERVICE_SHORT}dbbkp${CONFIG_SHORT}sa" >> $GITHUB_ENV
        TODAY=$(date +"%F")
        echo "DB_SERVER=${RESOURCE_NAME_PREFIX}-${SERVICE_SHORT}-${CONFIG_SHORT}-pg" >> $GITHUB_ENV
        if [ "${BACKUP_FILE}" == "schedule" ]; then
          BACKUP_FILE=${SERVICE_SHORT}_${CONFIG_SHORT}_${TODAY}
        elif [ "${BACKUP_FILE}" == "default" ]; then
          BACKUP_FILE=${SERVICE_SHORT}_${CONFIG_SHORT}_adhoc_${TODAY}
        else
          BACKUP_FILE=${BACKUP_FILE}
        fi
        echo "BACKUP_FILE=${BACKUP_FILE}" >> $GITHUB_ENV

    - name: Backup ${{ env.DEPLOY_ENV }} postgres
      uses: DFE-Digital/github-actions/backup-postgres@master
      with:
        storage-account: ${{ env.STORAGE_ACCOUNT_NAME }}
        resource-group: ${{ env.RESOURCE_GROUP_NAME }}
        app-name: ${{ env.SERVICE_NAME }}-${{ env.DEPLOY_ENV }}
        namespace: ${{ env.NAMESPACE }}
        cluster: ${{ env.CLUSTER }}
        azure-client-id: ${{ secrets.AZURE_CLIENT_ID }}
        azure-tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        azure-subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        backup-file: ${{ env.BACKUP_FILE }}.sql
        db-server-name: ${{ inputs.db-server }}
        slack-webhook: ${{ secrets.SLACK_WEBHOOK }}

  restore_and_sanitise:
    needs: [backup]
    name: Restore and sanitise
    if: ${{ github.event_name == 'schedule' }}
    runs-on: ubuntu-latest
    environment:
      name: production
    services:
      postgres:
        image: postgres:11.10
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
        - 5432:5432
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5

    steps:
    - uses: actions/checkout@v4
      name: Checkout

    - name: Set environment variables
      run: |
        source global_config/production.sh
        TODAY=$(date +"%F")
        BACKUP_FILE=${SERVICE_SHORT}_${CONFIG_SHORT}_${TODAY}.sql.gz
        echo "BACKUP_FILE=${BACKUP_FILE}" >> $GITHUB_ENV

    - uses: azure/login@v2
      with:
        tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        client-id: ${{ secrets.AZURE_CLIENT_ID }}

    - name: Set Connection String
      shell: bash
      run: |
        STORAGE_CONN_STR=$(az storage account show-connection-string -g s189p01-rtt-pd-rg -n s189p01rttdbbkppdsa --query 'connectionString')
        echo "::add-mask::$STORAGE_CONN_STR"
        echo "AZURE_STORAGE_CONNECTION_STRING=$STORAGE_CONN_STR" >> $GITHUB_ENV

    - name: Download Backup
      shell: bash
      run: |
        az config set extension.use_dynamic_install=yes_without_prompt
        az config set core.only_show_errors=true
        az storage blob download --container-name database-backup \
        --file ${{ env.BACKUP_FILE }} --name ${{ env.BACKUP_FILE }} \
        --connection-string '${{ env.AZURE_STORAGE_CONNECTION_STRING }}'

    - name: Install kubectl
      uses: DFE-Digital/github-actions/set-kubectl@master

    - uses: DFE-Digital/github-actions/set-kubelogin-environment@master
      with:
        azure-tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        azure-subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
        azure-client-id: ${{ secrets.AZURE_CLIENT_ID }}

    - name: K8 setup
      shell: bash
      run: |
        make ci production get-cluster-credentials
        make install-konduit

    - name: Setup postgres client
      uses: DFE-Digital/github-actions/install-postgres-client@master

    - name: Restore backup to aks productiondata database
      shell: bash
      run: |
        bin/konduit.sh -n bat-production -i ${{ env.BACKUP_FILE }} -c -t 7200 register-productiondata -- psql

    - name: Restore backup to aks analysis database
      shell: bash
      run: |
        bin/konduit.sh -n bat-production -i ${{ env.BACKUP_FILE }} -c -p ANALYSIS_DATABASE_URL -t 7200 register-production -- psql
        bin/konduit.sh -n bat-production -p ANALYSIS_DATABASE_URL -t 300 register-production -- psql -c 'GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO "${{ env.SQLPAD_USER }}"'
        bin/konduit.sh -n bat-production -p ANALYSIS_DATABASE_URL -t 300 register-production -- psql -c 'GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO "${{ env.SQLPAD_USER }}"'
      env:
        SQLPAD_USER: ${{ secrets.SQLPAD_USER }}

    - name: Disk cleanup
      shell: bash
      run: |
        sudo rm -rf /usr/local/lib/android || true
        sudo rm -rf /usr/share/dotnet || true
        sudo rm -rf /opt/ghc || true

    - name: Set env variable
      run: echo "SANITISED_FILE_NAME=register_sanitised_$(date +"%F")" >> $GITHUB_ENV

    - name: Create local Sanitised Database
      run: |
        createdb ${DATABASE_NAME} && gzip -d --to-stdout ${{ env.BACKUP_FILE }} | psql -d ${DATABASE_NAME}
      env:
        DATABASE_NAME: register_trainee_teachers
        PGUSER:  postgres
        PGPASSWORD: postgres
        PGHOST: localhost
        PGPORT: 5432

    - name: Remove backup file
      shell: bash
      run: |
        rm ${{ env.BACKUP_FILE }}

    - name: Sanitise the local Database
      run: |
        psql -d ${DATABASE_NAME} -f db/scripts/sanitise.sql
      env:
        DATABASE_NAME: register_trainee_teachers
        PGUSER:  postgres
        PGPASSWORD: postgres
        PGHOST: localhost
        PGPORT: 5432

    - name: Dump the Sanitised Database
      run: |
        pg_dump --encoding utf8 --compress=1 --clean --no-owner --if-exists -d ${DATABASE_NAME} -f ${SANITISED_FILE_NAME}.sql.gz
      env:
        DATABASE_NAME: register_trainee_teachers
        PGUSER:  postgres
        PGPASSWORD: postgres
        PGHOST: localhost
        PGPORT: 5432

    - name: Upload Sanitised Backup to Azure Storage
      run: |
        az storage blob upload --container-name database-backup \
        --file ${SANITISED_FILE_NAME}.sql.gz --name ${SANITISED_FILE_NAME}.sql.gz --overwrite \
        --connection-string '${{ secrets.AZURE_STORAGE_CONNECTION_STRING_SANITISED }}'
        rm ${SANITISED_FILE_NAME}.sql.gz

    - name: Check for Failure
      uses: ./.github/actions/send-slack-notification/
      if: ${{ failure() }}
      with:
        slack-title: Backup Failure
        slack-message: ':alert: Backup failure :sadparrot:'
        slack-webhook: ${{ secrets.SLACK_WEBHOOK }}

  # Temporarily suspend restore to staging to allow testing
  #
  # restore_staging:
  #   needs: [restore_and_sanitise]
  #   name: Restore database (staging)
  #   if: ${{ github.event_name == 'schedule' }}
  #   runs-on: ubuntu-latest
  #   environment:
  #     name: staging

  #   steps:
  #   - uses: actions/checkout@v4
  #     name: Checkout

  #   - name: Set env variable
  #     run: echo "SANITISED_FILE_NAME=register_sanitised_$(date +"%F")" >> $GITHUB_ENV

  #   - name: Download Backup
  #     run: |
  #       az storage blob download --container-name database-backup \
  #       --file ${SANITISED_FILE_NAME}.sql.gz --name ${SANITISED_FILE_NAME}.sql.gz \
  #       --connection-string '${{ secrets.AZURE_STORAGE_CONNECTION_STRING_SANITISED }}'

  #   - uses: azure/login@v2
  #     with:
  #       tenant-id: ${{ secrets.AZURE_TENANT_ID }}
  #       subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  #       client-id: ${{ secrets.AZURE_CLIENT_ID }}

  #   - name: Install kubectl
  #     uses: DFE-Digital/github-actions/set-kubectl@master

  #   - uses: DFE-Digital/github-actions/set-kubelogin-environment@master
  #     with:
  #       azure-tenant-id: ${{ secrets.AZURE_TENANT_ID }}
  #       azure-subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  #       azure-client-id: ${{ secrets.AZURE_CLIENT_ID }}

  #   - name: K8 setup
  #     shell: bash
  #     run: |
  #       make ci staging get-cluster-credentials
  #       make install-konduit

  #   - name: Restore backup to staging database
  #     shell: bash
  #     run: |
  #       bin/konduit.sh -n bat-staging -i ${SANITISED_FILE_NAME}.sql.gz -c -t 7200 register-staging -- psql

  #   - name: Check for Failure
  #     uses: ./.github/actions/send-slack-notification/
  #     if: ${{ failure() }}
  #     with:
  #       slack-title: Staging Restore Failure
  #       slack-message: ':alert: Daily restore failure for staging :sadparrot:'
  #       slack-webhook: ${{ secrets.SLACK_WEBHOOK }}
